{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Python Course - Tutorial 8",
   "id": "66a6f51e4df85143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1 (Data Visualization with Matplotlib)\n",
    "\n",
    "Consider the music.db database provided in our GitHub repository. Create a histogram\n",
    "that shows the distribution of the total number of items purchased per invoice. Add\n",
    "appropriate axis labels, a title, and a grid to the plot. Save the plot in a designated\n",
    "directory named images/ and exclude this directory from version control."
   ],
   "id": "d29f8fc5931999b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to the SQLite database and read the 'invoice_items' table into a DataFrame\n",
    "with sqlite3.connect(\"../music.db\") as conn:\n",
    "    invoices_items_df = pd.read_sql_query(\"SELECT * FROM invoice_items\", conn)\n",
    "\n",
    "# Group the data by 'InvoiceId' and calculate the total quantity of items per invoice\n",
    "invoice_totals = invoices_items_df.groupby(\"InvoiceId\")[\"Quantity\"].sum()\n",
    "\n",
    "# Plot a histogram of the total quantities of items per invoice\n",
    "plt.hist(invoice_totals, bins=20)\n",
    "plt.xlabel(\"Total Quantity of Items per Invoice\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Invoice Quantities\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Create an 'images' directory if it doesn't already exist and save the plot\n",
    "pathlib.Path(\"images\").mkdir(exist_ok=True)\n",
    "plt.savefig(\"images/invoice_quantity_histogram.jpg\")\n",
    "\n",
    "# Display the histogram plot\n",
    "plt.show()\n"
   ],
   "id": "b8811f8deff61eb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2 (Linear Regression with Statsmodels)\n",
    "\n",
    "Using the `music.db` database, investigate the relationship between track length and the number of times a track has been streamed. Treat track length (in milliseconds) as the **independent variable** and the total number of streams (from the play histories table) as the **dependent variable**.\n",
    "\n",
    "*Note:* Since track length does not have mean zero, you should include an intercept in the model. For this, you can use `X = sm.add_constant(X, prepend=True)` before fitting the model.\n"
   ],
   "id": "dc142eaf6212321c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statsmodels.api as sm\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to the SQLite database and fetch data from 'tracks' and 'play_histories' tables\n",
    "conn = sqlite3.connect(\"../music.db\")\n",
    "tracks_df = pd.read_sql_query(\"SELECT TrackId, Milliseconds FROM tracks\", conn)\n",
    "play_histories_df = pd.read_sql_query(\"SELECT * FROM play_histories\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Aggregate the number of streams for each track\n",
    "stream_counts = play_histories_df.groupby(\"TrackId\").size().reset_index(name=\"NumStreams\")\n",
    "\n",
    "# Merge the track data with the stream counts on 'TrackId'\n",
    "merged_df = pd.merge(tracks_df, stream_counts, on=\"TrackId\", how=\"inner\")\n",
    "\n",
    "# Prepare the independent variable (track length) and dependent variable (number of streams)\n",
    "X = merged_df[\"Milliseconds\"].astype(float)\n",
    "y = merged_df[\"NumStreams\"].astype(float)\n",
    "X = sm.add_constant(X, prepend=True)  # Add a constant term for the regression model\n",
    "\n",
    "# Fit a linear regression model using Ordinary Least Squares (OLS)\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Plot the data and the regression line\n",
    "plt.scatter(merged_df[\"Milliseconds\"], merged_df[\"NumStreams\"], label=\"Data\", alpha=0.7)\n",
    "plt.plot(merged_df[\"Milliseconds\"], model.predict(X), color=\"red\", label=\"Fit\")\n",
    "\n",
    "# Label the axes, add a title, grid, and legend to the plot\n",
    "plt.xlabel(\"Track Length (ms)\")\n",
    "plt.ylabel(\"Number of Streams\")\n",
    "plt.title(\"Linear Regression: Number of Streams vs. Track Length\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "697b5ee533d04cb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 3 (Statistical Analysis with SciPy)\n",
    "\n",
    "The `northwind.db` database from our GitHub repository (`tutorials/data/northwind.db`) contains unit price and category information for various products. Write a function that takes two category names as input and performs a **t-test** to determine if the mean product unit prices of the two categories are significantly different. The function should return a boolean value indicating whether the difference is significant at a **95% confidence level** (i.e., whether the p-value is less than 0.05).\n"
   ],
   "id": "b98a9293008e57a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def has_significant_price_differences(category1, category2):\n",
    "    # Connect to the SQLite database and fetch data from 'Products' and 'Categories' tables\n",
    "    with sqlite3.connect(\"data/northwind.db\") as conn:\n",
    "        products_df = pd.read_sql_query(\"SELECT * FROM Products\", conn)\n",
    "        categories_df = pd.read_sql_query(\"SELECT * FROM Categories\", conn)\n",
    "\n",
    "    # Merge the products and categories data on 'CategoryID'\n",
    "    merged_df = pd.merge(products_df, categories_df, on=\"CategoryID\", how=\"inner\")\n",
    "\n",
    "    # Extract prices for the specified categories\n",
    "    cat1_prices = merged_df.loc[merged_df[\"CategoryName\"] == category1, \"UnitPrice\"]\n",
    "    cat2_prices = merged_df.loc[merged_df[\"CategoryName\"] == category2, \"UnitPrice\"]\n",
    "\n",
    "    # Perform an independent t-test to compare the two categories\n",
    "    t_stat, p_val = stats.ttest_ind(cat1_prices, cat2_prices)\n",
    "\n",
    "    # Print the test statistics and interpret the result\n",
    "    print(\"T-statistic:\", round(t_stat, 4))\n",
    "    print(\"P-value:\", round(p_val, 4))\n",
    "    if p_val < 0.05:\n",
    "        print(\"Reject null hypothesis: The means are different\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis: The means are the same\")\n",
    "        return False\n",
    "\n",
    "# Check for significant price differences between two categories\n",
    "result = has_significant_price_differences(\"Beverages\", \"Condiments\")\n",
    "print(result)\n"
   ],
   "id": "771d7ddefa85b3b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 4 (Optional: Additional Python Resources for Data Science)\n",
    "\n",
    "To further strengthen your skills in Python for data analysis and visualization, consider completing the following tasks:\n",
    "\n",
    "1. **Discover Additional Resources for Popular Python Packages**:  \n",
    "   - Read parts of [Python for Data Analysis](https://wesmckinney.com/book/) by Wes McKinney to enhance your knowledge of Pandas and NumPy for data manipulation.  \n",
    "   - Check out [The Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) by Jake VanderPlas, which covers essential tools like Matplotlib, SciPy, and Scikit-learn.  \n",
    "   - Review the [Matplotlib Cookbook](https://github.com/rougier/scientific-visualization-book) for hands-on examples of data visualization with Matplotlib.  \n",
    "   - Explore the documentation for [Seaborn](https://seaborn.pydata.org/) (for advanced statistical plots) and [Plotly](https://plotly.com/python/) (for interactive, web-based visualizations).  \n",
    "   - Visit [Claus Wilke's Data Visualization](https://clauswilke.com/dataviz/) for advice on creating effective visualizations.  \n",
    "   - Dive into the [Scientific Python Lectures](https://lectures.scientific-python.org/) to deepen your understanding of Python in scientific computing.  \n",
    "\n",
    "2. **Practice and Apply Your Skills**:  \n",
    "   - Challenge yourself with Python exercises using NumPy and Pandas on platforms like [StrataScratch](https://www.stratascratch.com), which offers real-world datasets and interview questions.  \n",
    "   - Explore practical problems and datasets on [Kaggle](https://www.kaggle.com).  \n",
    "\n",
    "3. **Choose Your Own Project**:  \n",
    "   - Alternatively, pick a project or topic that interests you and apply the concepts you've learned to it.\n"
   ],
   "id": "9ec12aba4ed625cb"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
